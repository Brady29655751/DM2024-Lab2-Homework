{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:ÈªÉÂ≠êËªí\n",
    "\n",
    "Student ID:113062614\n",
    "\n",
    "GitHub ID:Brady29655751\n",
    "\n",
    "Kaggle name:Brady Huang\n",
    "\n",
    "Kaggle private scoreboard snapshot:![](./img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction 2\n",
    "#### Participate in Kaggle Competition.\n",
    "\n",
    "I implemented my work in Kaggle notebook. Below is part of my work in Kaggle competition. <br/>\n",
    "The first part is provided by Kaggle originally to check the input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are provided by kaggle and check the input files.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, include the needed library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I've tried some data cleaning techniques, such as transform emoji into text and drop duplicates, but the result improves only a little. <br/>\n",
    "For public leaderboard, cleaning improves from 0.31545 to 0.32339. <br/>\n",
    "For private leaderboard, cleaning improves from 0.31230 to 0.31909."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is code without data cleaning.\n",
    "data = []\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is some code with data cleaning.\n",
    "import emoji\n",
    "import pandas as pd\n",
    "\n",
    "# This is emoji dict that replace specific emoji to text.\n",
    "# I don't include all emoji here since it's only for showing my work.\n",
    "emoji_dict = {\n",
    "    'üòÇ': '[joy]',\n",
    "    '‚ù§Ô∏è': '[love]',\n",
    "    'üò≠': '[cry]',\n",
    "    'üôè': '[pray]',\n",
    "    'üòò': '[kiss]',\n",
    "    'üî•': '[fire]',\n",
    "    'ü§î': '[think]',\n",
    "    'üòÅ': '[happy]',\n",
    "    'üëç': '[great]',\n",
    "}\n",
    "\n",
    "# This is the cleaning function.\n",
    "def clean_emoji(text):\n",
    "    for emj, emj_text in emoji_dict.items():\n",
    "        text = text.replace(emj, emj_text)\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows <b>part of</b> my preprocessing and feature extraction code. <br/>\n",
    "Originally, I use 20% of data for training, then 30%, and finally 50%. <br/>\n",
    "I don't use 100% data for training because the model I used cannot be accelerated by GPU. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify train and test by given identification.\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']\n",
    "\n",
    "# Use part of data to train the model. This percentage is changed during experiments.\n",
    "train_data_sample = train_data.sample(frac=0.5, random_state=97)\n",
    "\n",
    "# Get X and y for training\n",
    "y_train_data = train_data_sample['emotion']\n",
    "X_train_data = train_data_sample.drop(['tweet_id', 'emotion', 'identification', 'hashtags'], axis=1)\n",
    "\n",
    "# This train test split is used for splitting training and validation.\n",
    "# Here uses stratify to make sure the distribution is roughly the same as y.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_data, y_train_data, test_size=0.2, random_state=97, stratify=y_train_data\n",
    ")\n",
    "\n",
    "#### Feature Extraction\n",
    "# Use very basic TF-IDF. The max features is changed during experiments.\n",
    "# TF-IDF is fit with train and not test.\n",
    "tfidf = TfidfVectorizer(max_features=3000)  \n",
    "X = tfidf.fit_transform(X_train['text']).toarray()\n",
    "X_test = tfidf.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows my Label Encoder and Random Forest Model. <br/>\n",
    "This takes lots of time and memory when the TFIDF features grow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Random Forest\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Check Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Go for test dataset\n",
    "# This one is the testing data from leaderboard (identification = \"test\")\n",
    "X_test_data = test_data.drop(['tweet_id', 'identification', 'hashtags'], axis=1)\n",
    "X_test_data = tfidf.transform(X_test_data['text']).toarray()\n",
    "\n",
    "y_test_pred = clf.predict(X_test_data)\n",
    "\n",
    "# Inverse to original label and generate submissions.\n",
    "y_pred_labels = label_encoder.inverse_transform(y_test_pred)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['tweet_id'],\n",
    "    'emotion': y_pred_labels\n",
    "}, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is the explanation for my code. <br/>\n",
    "My experiment results are concluded in my report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction 3\n",
    "\n",
    "Report of my work is included in the pdf file in github repository.\n",
    "\n",
    "[report](./report.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
